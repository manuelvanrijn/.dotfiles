# ~/.codex/config.toml â€” managed by codex-1up (patch mode)
notify = ["~/.codex/notify.sh"]
profile = "yolo"
suppress_unstable_features_warning = true
web_search = "live"

[features]
collaboration_modes = true

[profiles.balanced]
approval_policy = "on-request"
sandbox_mode = "workspace-write"
model = "gpt-5.2"
model_reasoning_effort = "high"
personality = "pragmatic"
#model_reasoning_summary = "concise"

[profiles.safe]
approval_policy = "on-failure"
sandbox_mode = "read-only"
model = "gpt-5.1-codex"
model_reasoning_effort = "medium"
#model_reasoning_summary = "concise"

[profiles.yolo]
approval_policy = "never"
sandbox_mode = "danger-full-access"
model = "gpt-5.3-codex"
model_reasoning_effort = "medium"
model_reasoning_summary = "detailed"
tool_output_token_limit = 25000
model_auto_compact_token_limit = 233000

[tui]
notifications = true

[notice]
"hide_gpt-5.1-codex-max_migration_prompt" = true

[notice.model_migrations]
"gpt-5.2" = "gpt-5.2-codex"
"gpt-5.1" = "gpt-5.2-codex"
"gpt-5.1-codex-max" = "gpt-5.2-codex"

[mcp_servers.augment-context-engine]
command = "auggie"
args = ["--mcp", "--mcp-auto-workspace"]

[mcp_servers.shadcn]
command = "npx"
args = ["shadcn@latest", "mcp"]
